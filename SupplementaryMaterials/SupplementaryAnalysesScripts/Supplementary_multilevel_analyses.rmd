<!-- Supplementary Analyses B -->

```{r analysis-preferences}
# Seed for random number generation
set.seed(17042023)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

```

# Supplementary Analyses B: Multilevel Analyses

This appendix contains the multilevel model versions of the models used to test Hypothesis 3, 5, & 6 in the main text (additional multilevel models can be found in [Supplementary Analyses C](Supplementary_omega_analyses.Rmd) and [Supplementary Analyses D](Supplementary_initial_QMP_analyses.Rmd)). These models were omitted from the main text because the sample sizes were not large enough to support multilevel modelling. Guidelines suggest to have at least within the range of 10 to 30 groups with 10 to 30 cases each for multilevel models, with more groups and cases each being necessary for more complex models, such as random-slope models (Kreft, 1996; Snijders and Bosker, 1993; Hox, 1998, 2010). For Hypothesis 3 we had `r nrow(table(data_h23$g))` groups with on average `r round(mean(table(data_h23$g)),3)` cases. For Hypothesis 5 and 6 we had `r nrow(table(data_h456_replications$many_labs_version))` groups with on average `r mean(table(data_h456_replications$many_labs_version))` cases. Therefore, while we have may have had a sufficient number of cases per group for simple models, we likely lacked a sufficient number of groups to estimate multilevel models, especially more complex models. In 4 (all random slope models) of the 12 multilevel models we ran we encountered convergence issues, further illustrating that our sample size was likely inadequate for these models.

Additionally, our dependent variable (replication success) was at the group level in all of these models. In this case, it is advised in most cases to run analyses with all variables aggregated at the group level and adjust the standard errors of the coefficients using White's heteroscedasticity adjustment (Foster-Johnson & Kromrey, 2018). We therefore also show analyses with this adjustment for Hypothesis 3. Aggregation would make little sense for Hypothesis 5 and 6, as there were only four groups here, which would lead to a model with only 4 cases.

## Hypothesis 3, Nested Within Replication Sets

### Explanation of Relevance

In this data, replication attempts at different lab locations can be seen as nested within a replication set. To see if this nesting might impact the analyses of hypothesis 3, multilevel models are included here as sensitivity checks.

### Model

The specific models used were a multilevel logistic regression random intercept and random slope model. The dependent variable remains replication success at the replication set level, while Cronbach's alpha was no longer averaged across locations.

```{r Hypothesis3MultilevelModelSensitivityAnalyses, warning = FALSE}
## sensitivity analyses.
# running a random intercept multilevel logistic model
H3_test_result_int_sensitivity_alpha <- apa_print(glmer(formula = replication_success ~ 1 
                                                + alpha + (1|g), family = 
                                                binomial(), data = 
                                                data_h23))

# same as for non-multilevel model

# running a random slope multilevel logistic model
H3_test_result_slp_sensitivity_alpha <- apa_print(glmer(formula = replication_success ~ 1 
                                                + alpha + (1 + alpha|g), 
                                                family = binomial(), data =
                                                data_h23))

# did not converge
```

### Results

The random-intercept model did not show a significant relation between reliability and replication (`r H3_test_result_int_sensitivity_alpha$full_result$alpha`). This corroborates the findings in the article, only now using a random intercept multilevel model. However, also similarly to the results in the article and perhaps even more so for the multilevel model, the small sample size for these tests means that caution should be taken in interpreting these results. The random slope model did not converge.


## Hypotheses 5 & 6, nested within Many Labs

### Explanation of Relevance

The models used in the article to test Hypotheses 5 & 6 had independence of observations as an assumption, the observations here referring to a replication set. this is known to be false since the data is nested within four separate Many Labs projects.

### Models

To test if this nested structure might influence the relations described in Hypothesis 5 & 6, random intercept, and random slope multilevel models with each Many Labs project as a group were implemented as sensitivity analyses. As of writing this article the *betareg* package does not allow for estimation of multilevel models. As an approximation, Gaussian random-intercept multilevel models were implemented using the *lmer* function from the *lme4* package [@R-lme4]. The outcome QMP ratio variable was transformed using the logit link function (the default link function in the *betareg* package) to fit the Gaussian model.

```{r Hypotheses5And6SensitivityAnalyses, warning = FALSE}
## Hypothesis 5 sensitivity test using a random intercept and random slope Gaussian model.
# create dummy H5 dataframe for use in sensitivity test
data_h5_sens <- data_h456_replications
data_h5_sens <- data_h5_sens[data_h5_sens$hypothesis_support != "Unclear",]
data_h5_sens$hypothesis_support <- droplevels.factor(data_h5_sens$hypothesis_support)

# convert outcome variable to be usable with Gaussian distribution via
# logit transform.
data_h5_sens$QMP_REV <- log(data_h5_sens$QMP_REV_ratio /(1 - data_h5_sens$QMP_REV_ratio))


# running the models
random_intercept_h5_REV <- apa_print(lmer(formula = QMP_REV ~ 1 + hypothesis_support + (1|many_labs_version), data = data_h5_sens))

random_slope_h5_REV <- apa_print(lmer(formula = QMP_REV ~ 1 + hypothesis_support + (1 + hypothesis_support|many_labs_version), data = data_h5_sens))


## Hypothesis 6 sensitivity test using a random intercept and random slope Gaussian model.
# create dummy H6 dataframe for use in sensitivity test
data_h6_sens <- data_h6

# convert outcome variable to be usable with Gaussian distribution via
# logit transform. 
data_h6_sens$QMP_REV <- log(data_h6_sens$QMP_REV_ratio /(1 - data_h6_sens$QMP_REV_ratio))
data_h6_sens$Rep_QMP_REV <- log(data_h6_sens$Rep_QMP_REV_ratio /(1 - data_h6_sens$Rep_QMP_REV_ratio))

# running the models with revised QMP ratio's
random_intercept_h6_REV <- apa_print(lmer(formula = Rep_QMP_REV ~ 1 + QMP_REV + (1|many_labs_version), data = data_h6_sens))

random_slope_h6_REV <- apa_print(lmer(formula = Rep_QMP_REV ~ 1 + QMP_REV + (1 + QMP_REV|many_labs_version), data = data_h6_sens))

# n of mod ratio's that are present (check)
H6_n_check_results_REV <- betareg(Rep_op_REV_ratio ~ mod_REV_ratio, data = data_h6)$n

```

### Results

For Hypothesis 5, the sensitivity analyses using a random-intercept multilevel regression found a similar significant association as that found by the main test (`r random_intercept_h5_REV$full_result$hypothesis_supportTRUE`). This result corroborates Hypothesis 5. The random slope model did not converge.

For Hypothesis 6, the sensitivity analyses using a random intercept logistic multilevel model resulted in non-significant results, which is different from the results found with the main test (revised protocol: `r random_intercept_h6_REV$full_result$QMP_REV`). This result does not corroborate Hypothesis 6. The random slope model did not converge.

# References
Foster-Johnson, L., & Kromrey, J. D. (2018). Predicting group-level outcome variables: An empirical comparison of analysis strategies. *Behavior Research Methods*, *50(6)*, 2461â€“2479. <https://doi.org/10.3758/s13428-018-1025-8>

Hox, J. (1998). Multilevel Modeling: When and Why. In: Balderjahn, I., Mathar, R., Schader, M. (eds) Classification, Data Analysis, and Data Highways. Studies in Classification, Data Analysis, and Knowledge Organization. *Springer, Berlin, Heidelberg*. <https://doi.org/10.1007/978-3-642-72087-1_17>

Hox, J., Moerbeek, M., & van de Schoot, R. (2010). Multilevel Analysis: Techniques and Applications, Second Edition (2nd ed.). *Routledge*. <https://doi.org/10.4324/9780203852279>

Kreft, I. G. (1996). Are multilevel techniques necessary? An overview, including simulation studies. *Unpublished manuscript, California State University, Los Angeles*.

Snijders, T. A. B., & Bosker, R. J. (1993). Standard Errors and Sample Sizes for Two-Level Research. *Journal of Educational Statistics*, *18(3)*, 237-259. <https://doi.org/10.3102/10769986018003237>

